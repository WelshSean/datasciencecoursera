mat2 = matrix(c(2, 4, 3, 1, 5, 4, 4, 4, 2), nrow=3, ncol=3, byrow = TRUE)
mat2
makeCacheMatrix(mat2)
b <-makeCacheMatrix(mat2)
cacheSolve(b)
cacheSolve(b)
cacheSolve(b)
b <-makeCacheMatrix(mat)
cacheSolve(b)
cacheSolve(b)
source('~/DataScience/ProgrammingAssignment2/cachematrix.R')
source('~/DataScience/ProgrammingAssignment2/cachematrix.R')
setwd("Question 1
The American Community Survey distributes downloadable data about United States communities. Download the 2006 microdata survey about housing for the state of Idaho using download.file() from here:
https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv
and load the data into R. The code book, describing the variable names is here:
https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FPUMSDataDict06.pdf
How many properties are worth $1,000,000 or more?
164
24
53
31
")
exit
quit()
library(swirl)
install_from_swirl("Getting and Cleaning Data")
swirl
swirl()
mydf <- read.csv(path2csv, stringsAsFactors = FALSE)
dim(mydf)
head(mydf)
library(dplyr)
packageVersion("dplyr")
cran <- tbl_df(mydf)
rm("mydf")
cran
?select
select(cran, ip_id, package, country)
5:20
select(cran, r_arch:country)
select(cran, country, r_arch)
select(cran, country:r_arch)
cran
select(cran,-time)
-5:20
-(5:20)
select(cran,-(x:size))
select(cran,-(X:size))
filter(cran, package =="swirl")
filter(cran, r_version == "3.1.1, country == "US")
filter(cran, r_version == "3.1.1", country == "US")
?Comparison
filter(cran, r_version <= "3.0.2", country == "IN")
filter(cran, country == "US" | country == "IN")
filter(cran, size > 100500, r_os -- "linux-gnu")
filter(cran, size > 100500, r_os == "linux-gnu")
is.na(3, 5, NA, 10)
is.na(c(3, 5, NA, 10))
!is.na(c(3, 5, NA, 10))
filter(cran, !is.na(r_version)
filter(cran, !is.na(r_version)
filter(cran, !is.na(r_version))
cran2 <- select(cran, size:ip_id)
arrange(cran2, ip_id)
arrange(cran2, desc(ip_id)
arrange(cran2, desc(ip_id))
arrange(cran2, desc(ip_id))
arrange(cran2, package, ip_id)
arrange(cran2, country, desc(r_version), ip_id)
cran3 <- select(cran, ip_id, package, size)
cran3
mutate(cran3, size_mb = size/ 2^20)
mutate(cran3, size_gb = size/ 2^10)
mutate(cran3, size_mb = size/ 2^20, size_gb - size_mb/2^10)
mutate(cran3, size_mb = size/ 2^20, size_gb = size_mb/2^10)
cran3
mutate(cran3, correct_size = size + 1000)
summarize(cran, avg_bytes = mean(size))
library(dplyr)
cran <- tbl_df(mydf)
rm("mydf")
cran
?group_by
by_package <- group_by(cran, package)
by_package
summarize(by_package, mean(size))
?n
n(by_package)
by_package
n(by_package)
n()
summarize(by_package, count = n())
summarize(by_package, count = n(), unique = n_distinct(ip_id))
summarize(by_package, count = n(), unique = n_distinct(ip_id), countries = n_distinct(country))
summarize(by_package, count = n(), unique = n_distinct(ip_id), countries = n_distinct(country), avg_bytes=mean(size))
submit()
pack_sum
quantile(pack_sum$count, probs = 0.99)
pack_sum
top_counts <- filter(pack_sum, count > 679)
top_counts
View(top_counts)
top_counts_sorted <- arrange(top_counts, desc(count))
View(top_counts_sorted)
quantile(pack_sum$unique, probs = 0.99)
top_unique <- filter(pack_sum, count > 465)
top_unique <- filter(pack_sum, unique > 465)
View(top_unique)
top_unique_sorted <- arrange(top_unique, desc(unique))
View(top_unique_sorted)
submit()
submit()
submit()
View(Result3)
View(result3)
submit()
submit()
submit()
submit()
library(tidyr)
students
?gather
gather(students, sex, count, -grade)
students2
res <- gather(students2, sex_class, count)
res <- gather(students2, sex_class, count , -grade)
res
?seperate
?separate
separate(res, sex_class, c("sex", "class"))
submit()
students3
?father
?gather
submit
submit()
submit()
submit()
?spread
students3
submit()
submit()
students3
submit()
reset()
students3
submit()
submit()
submit()
submit()
extract_numeric("class5")
?mutate
submit()
submit()
submit()
submit()
?extract_numeric
submit()
submit()
submit()
rest()
reset()
submit()
submit()
View(students3)
submit()
students3 %>%
gather(class, grade, class1:class5, na.rm = TRUE) %>%
spread(test, grade)
students3 %>%
gather(class, grade, class1:class5, na.rm = TRUE) %>%
spread(test, grade) %>%
mutate(class = extract_numeric(class))
submit()
quit()
swirl()
library(swirl)
swirl()
?mutate
students3 %>%
gather(class, grade, class1:class5, na.rm = TRUE) %>%
spread(test, grade
)
submit()
students3 %>%
gather(class, grade, class1:class5, na.rm = TRUE) %>%
spread(test, grade) %>%
mutate(class = extract_numeric(class))
students3 %>%
gather(class, grade, class1:class5, na.rm = TRUE) %>%
spread(test, grade)
students3 %>%
gather(class, grade, class1:class5, na.rm = TRUE) %>%
spread(test, grade) %>%
mutate(class = extract_numeric(class))
submit()
head(students4)
students4
students4
submit()
students4
submit()
?unique
submit()
student_info <- students4 %>%
select(id, name, sex) %>%
unique() %>%
### Your code here %>%
print
student_info <- students4 %>%
select(id, name, sex) %>%
### Your code here %>%
print
student_info <- students4 %>%
select(id, name, sex) %>%
unique() %>%
### Your code here %>%
print
submit()
submit()
passed
failed
passed <- mutate(passed, status="passed")
passed <- mutate(failed, status="failed")
failed <- mutate(failed, status="failed")
passed <- mutate(passed, status="passed")
?bind_rows
bind_rows(passed, failed)
sat
?select
?gather
?seperate
?separate
sat %>%
select(-contains(total))
sat %>%
select(-contains("total"))
sat %>%
select(-contains("total")) %>%
gather(part_sex, count, -score_range)
at %>%
select(-contains("total")) %>%
gather(part_sex, count, -score_range) %>%
separate(part_sex,c("part","sex"))
sat %>%
select(-contains("total")) %>%
gather(part_sex, count, -score_range) %>%
separate(part_sex,c("part","sex"))
submit()
?group_by
sat %>%
select(-contains("total")) %>%
gather(part_sex, count, -score_range) %>%
separate(part_sex, c("part", "sex")) %>%
group_by("part", "sex")
sat %>%
select(-contains("total")) %>%
gather(part_sex, count, -score_range) %>%
separate(part_sex, c("part", "sex")) %>%
group_by(part, sex)
submit()
Sys.getlocale("LC_TIME")
library(lubridate)
help(package=lubridate)
today()
this_day <- today()
this_day
year(this_day)
wday(this_date)
wday(this_day)
wday(this_day, label=TRUE)
wday(this_day)
wday(this_day, label=TRUE)
this_moment <- now()
this_moment
second(this_moment)
ymd("1989-05-17")
my_date <- ymd("1989-05-17")
my_date
class(my_date)
ymd("1989 May 17")
mdy("March 12, 1975")
dmy(25081985)
ymd("192012")
ymd("1920-1-2")
dtl
dt1
ymd_hms(dt1)
hms("03:22:14")
dt2
ymd(dt2)
update(this_moment, hours = 8, minutes = 34, seconds = 55)
thus_moment
this_moment
update(this_moment, now())
update(this_moment, hours=10, minutes=16, seconds=0
)
update(this_moment, hours=10, minutes=16, seconds=0)
this_moment <- update(this_moment, hours=10, minutes=16, seconds=0)
this_moment
nyc <- now("America/New_York")
nyc
depart <- nyc +days(2)
depart
depart <- update(depart, hours=17, minutes=34)
depart
arrive <- depart +hours(15) + minutes(5)
arrive <- depart +hours(15) + minutes(50)
with_tz
?with_tz
with_tz(arrive, tzone = "Asia/Hong_Kong")
arrive <- with_tz(arrive, tzone = "Asia/Hong_Kong")
arrive
last_time <- mdy("June 17, 2008", tz=Singapore)
last_time <- mdy("June 17, 2008", tz="Singapore")
last_time
?new_interval
how_long <- new_interval( last_time, arrive)
as.period(how_long)
stopwatch()
install.packages("httr")
install.packages("httr")
?oauth_app
library(httr)
oauth_endpoints("github")
myapp <- oauth_app("github", "c29083488b7d5250b4ce")
library(httr)
# 1. Find OAuth settings for github:
#    http://developer.github.com/v3/oauth/
oauth_endpoints("github")
# 2. Register an application at https://github.com/settings/applications;
#    Use any URL you would like for the homepage URL (http://github.com is fine)
#    and http://localhost:1410 as the callback url
#
#    Insert your client ID and secret below - if secret is omitted, it will
#    look it up in the GITHUB_CONSUMER_SECRET environmental variable.
myapp <- oauth_app("github", "c29083488b7d5250b4ce")
# 3. Get OAuth credentials
github_token <- oauth2.0_token(oauth_endpoints("github"), myapp)
install.packages("httpuv")
library(httr)
# 1. Find OAuth settings for github:
#    http://developer.github.com/v3/oauth/
oauth_endpoints("github")
# 2. Register an application at https://github.com/settings/applications;
#    Use any URL you would like for the homepage URL (http://github.com is fine)
#    and http://localhost:1410 as the callback url
#
#    Insert your client ID and secret below - if secret is omitted, it will
#    look it up in the GITHUB_CONSUMER_SECRET environmental variable.
myapp <- oauth_app("github", "c29083488b7d5250b4ce")
# 3. Get OAuth credentials
github_token <- oauth2.0_token(oauth_endpoints("github"), myapp)
# 4. Use API
gtoken <- config(token = github_token)
req <- GET("https://api.github.com/rate_limit", gtoken)
stop_for_status(req)
content(req)
req <- GET("https://api.github.com", gtoken)
stop_for_status(req)
content(req)
req <- GET("https://api.github.com/users/jtleek/repos", gtoken)
stop_for_status(req)
content(req)
req <- GET("https://api.github.com/users/jtleek/repos/datasharing", gtoken)
stop_for_status(req)
req <- GET("https://api.github.com/users/jtleek/repos", gtoken)
stop_for_status(req)
content(req)
?stop_for_status
install.packages("jsonlite")
json1 <- content(req)
json2 <- jsonlite::fromJSON(toJSON(json1))
json2 <- jsonlite::fromJSON(jsonlite::toJSON(json1))
json2
View(json2)
req <- GET("https://api.github.com/users/jtleek/repos/datasharing/events", gtoken)
stop_for_status(req)
json1 <- content(req)
json2 <- jsonlite::fromJSON(jsonlite::toJSON(json1))
req <- GET("https://api.github.com/users/jtleek/datasharing/events", gtoken)
stop_for_status(req)
json1 <- content(req)
json2 <- jsonlite::fromJSON(jsonlite::toJSON(json1))
req <- GET("https://api.github.com/repos/jtleek/datasharing/events", gtoken)
stop_for_status(req)
json1 <- content(req)
json2 <- jsonlite::fromJSON(jsonlite::toJSON(json1))
View(json2)
View(json2)
req <- GET("https://api.github.com/repos/jtleek/datasharing", gtoken)
stop_for_status(req)
json1 <- content(req)
json2 <- jsonlite::fromJSON(jsonlite::toJSON(json1))
View(json2)
install.packages("sqldf")
?read.csv
download.file("d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06pid.csv","ACSz.csv",method="curl")
acs <- read.csv("ACSz.csv")
acs
library(sqldf)
sqldf("select * from acs where AGEP < 50")
sqldf("select pwgtp1 from acs where AGEP < 50")
sqldf("select distinct AGEP from acs")
con <- url("http://biostat.jhsph.edu/~jleek/contact.html ")
htmlcode <- readlines(con)
htmlcode <- readLines(con)
close(con)
htmlcode
class(htmlcode)
htmlcode[1:9]
nchar(htmlcode[10])
nchar(htmlcode[10,20,30,100])
nchar(htmlcode[c(10,20,30,100)])
download.file("http://www.cpc.ncep.noaa.gov/data/indices/wksst8110.for","for.for",method="curl")
?read
?read,file
?read.file
file <- read.for("for.for")
file <- read.fortran("for.for")
?read.fortran
?readt.table
?read.table
file <- read.table("for.for")
file <- read.table("for.for", skip=1)
??fixed
?read,fortran
?read.fortran
?read.fwf
file <- read.fwf("for.for", skip=2, widths=c(15,13,13,13,9))
View(file)
file <- read.fwf("for.for", skip=3, widths=c(15,13,13,13,9))
View(file)
file <- read.fwf("for.for", skip=3, widths=c(10,-5, 4, 4, -5, 4, 4, -5, 4, 4, -5, 4, 4))
View(file)
sum(file[4])
class(file[4])
class(file[,4])
file[,4]
sum(file[,4])
file <- read.fwf("for.for", skip=4, widths=c(10,-5, 4, 4, -5, 4, 4, -5, 4, 4, -5, 4, 4))
sum(file[,4])
View(file)
?sum
head (file)
download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fwksst8110.for","for.for",method="curl")
#file <- read.fortran("for.for")
#file <- read.fwf("for.for", skip=3, widths=c(15,13,13,13,9))
file <- read.fwf("for.for", skip=4, widths=c(10,-5, 4, 4, -5, 4, 4, -5, 4, 4, -5, 4, 4))
sum(file[,4])
install.packages("devtools")
devtools::install_github("twitter/AnomalyDetection")
library(AnomalyDetection)
data(raw_data)
res = AnomalyDetectionTs(raw_data, max_anoms=0.02, direction='both', plot=TRUE)
res$plot
View(raw_data)
res = AnomalyDetectionTs(raw_data, max_anoms=0.02, direction='both', plot=TRUE)
res = AnomalyDetectionTs(raw_data, max_anoms=0.1, direction='both', plot=TRUE)
res$plot
res = AnomalyDetectionTs(raw_data, max_anoms=0.02, direction='both', plot=TRUE)
res$plot
res = AnomalyDetectionTs(raw_data, max_anoms=0.5, direction='both', plot=TRUE)
res = AnomalyDetectionTs(raw_data, max_anoms=0.3, direction='both', plot=TRUE)
res = AnomalyDetectionTs(raw_data, max_anoms=0.02, direction='both', only_last="day", plot=TRUE)
res$plot
res = AnomalyDetectionTs(raw_data, max_anoms=0.3, direction='both', plot=TRUE)
?AnamalyDetectionTs
?AnomalyDetectionTs
?read.csv
read.csv("/tmp/cpu", stringsAsFactors=FALSE)
z <- read.csv("/tmp/cpu", stringsAsFactors=FALSE)
z
raw_data
res2 = AnomalyDetectionTs(z, max_anoms=0.02, direction='both', plot=TRUE)
z <- read.csv("/tmp/cpu", stringsAsFactors=FALSE)
z
res2 = AnomalyDetectionTs(z, max_anoms=0.02, direction='both', plot=TRUE)
View(z)
?AnomalyDetectionTs
class(raw_data)
class(z)
class(z[,1])
class(raw_data[,1])
res2 = AnomalyDetectionTs(z, max_anoms=0.02, direction='both', plot=TRUE)
?detect_anoms
res2 = AnomalyDetectionTs(z, max_anoms=0.02, direction='both', plot=TRUE, piecewise_median_period_weeks = 0.0001)
AnomalyDetectionVec(z[,2], max_anoms=0.02, period=1440, direction='both', only_last=FALSE, plot=TRUE)
AnomalyDetectionVec(z[,2], max_anoms=0.02, period=5, direction='both', only_last=FALSE, plot=TRUE)
AnomalyDetectionVec(z[,2], max_anoms=0.02, period=20, direction='both', only_last=FALSE, plot=TRUE)
AnomalyDetectionVec(z[,2], max_anoms=0.02, period=40, direction='both', only_last=FALSE, plot=TRUE)
AnomalyDetectionVec(z[,2], max_anoms=0.2, period=40, direction='both', only_last=FALSE, plot=TRUE)
head(z)
head(z,2)
AnomalyDetectionVec(z[,2], max_anoms=0.4, period=40, direction='both', only_last=FALSE, plot=TRUE)
AnomalyDetectionVec(z[,2], max_anoms=0.02, period=40, direction='both', only_last=FALSE, plot=TRUE)
AnomalyDetectionVec(z[,2], max_anoms=0.2, period=40, direction='both', only_last=FALSE, plot=TRUE)
setwd("/home/sean/DataScience/datasciencecoursera")/Exploratory-Data-Analysis/project2)
setwd("/home/sean/DataScience/datasciencecoursera/Exploratory-Data-Analysis/project2")
ls()
NEI <- readRDS("summarySCC_PM25.rds")
SCC <- readRDS("Source_Classification_Code.rds")
setwd("/home/sean/DataScience/datasciencecoursera/Exploratory-Data-Analysis/project2")
head("NEI")
head(NEI)
head(SCC)
View(NEI)
View(SCC)
?merge
df <- merge(NEI, SCC, by="SCC")
View(df)
