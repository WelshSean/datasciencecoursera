---
title: Analysis of NOAA Storm Data to Investigate the Effect of Storms on Public Health
  and the Economy
author: "Sean Clarke"
date: "19/05/2015"
output: html_document
---

# Synopsis

In this report we aim to investigate the impact of Weather Events upon the Population Health and the Economy of the US. More specifically we aim to answer two questions. Which types of events are most harmful with respect to Population Health and which types of events have the greatest economic consequences. To investigate these we obtained data from the NOAA storm database which has data describing weather events since the 1950s. We discovered that Extreme Storms (eg Hurricanes and Tornados) are certainly the most harmful events with respect to the health of the population. Extreme Storms and Floods appear to be almost equally impactful upon the economy of the US, however the data pertaining to Floods needs more attention as there are some suspiciously large outliers that could be skewing the statistics. The NOAA data in general seems to be extremely messy with some parts appearing to be extremely dubious in their reliability. Further detailed analysis of the issues would be helpful in terms of maximising the value of this resource.


# Data Processing

I obtained data from the U.S. National Oceanic and Atmospheric Administration's (NOAA) storm database which records the details of major weather events in the US along with estimates of their impact on the population and economy.

## Reading in the data

Firstly we download the file and unzip it in the code in order to help to ensure reproducability. The file is provided on the NOAA website but for the purposes of this exercise has also been [mirrored seperately](https://d396qusza40orc.cloudfront.net/repdata%2Fdata%2FStormData.csv.bz2). The file is a CSV file that is served up compressed using bzip2.

```{r cache = TRUE}
DataDir <- "Data"
FilePath <- paste(DataDir, "Stormdata.csv.bz2", sep="/")

dir.create(DataDir, showWarnings=FALSE) 

## Only download if the file doesnt exist
if (! file.exists(FilePath)){
download.file("https://d396qusza40orc.cloudfront.net/repdata%2Fdata%2FStormData.csv.bz2",FilePath , method="curl")
}

## No need to decompress, read.csv knows what to do
## ColsToKeep used to select interesting columns
ColsToKeep <- c("BGN_DATE", "BGN_TIME", "TIME_ZONE", "STATE", "EVTYPE", "FATALITIES", "INJURIES", "PROPDMG", "PROPDMGEXP", "CROPDMG", "CROPDMGEXP")
StormData <- read.csv(FilePath, stringsAsFactors = FALSE)[,ColsToKeep]
```

The dataset is massive so we take the opportunity to drop the columns that we have no interest in at this point. We keep the following columns `r ColsToKeep`.

After reading in this dataset we take the chance to see what the structure of the dataset looks like.

```{r}
dim(StormData)
head(StormData)
```

## Processing the Data


Next we want to tidy up the data - first of all we need to combine PROPDMG/PROPDMGEXP and CROPDMG/CROPDMGEXP. The "EXP" columns provide the exponentiation for the value stored in the corresponding "DMG" column. The symbols, K, M and B respectively representing 10^3, 10^6 and 10^9.

There is however a complication - there are additional values in this column which arent well described in the information page.

```{r}
unique(StormData$PROPDMGEXP)
unique(StormData$CROPDMGEXP)
```
We next investigate how important the undefined symbols are in this range

```{r}
require(dplyr)
aggregate(StormData$PROPDMGEXP, by=list(StormData$PROPDMGEXP), FUN=length)
aggregate(StormData$CROPDMGEXP, by=list(StormData$PROPDMGEXP), FUN=length)
StormData %>%
    filter(PROPDMGEXP %in% c("K","M","B", "")) %>%
    summarise(Total=n())
StormData %>%
    filter(!(PROPDMGEXP %in% c("K","M","B", ""))) %>%
    summarise(Total=n())
StormData %>%
    filter(CROPDMGEXP %in% c("K","M","B", "")) %>%
    summarise(Total=n())
StormData %>%
    filter(!(CROPDMGEXP %in% c("K","M","B", ""))) %>%
    summarise(Total=n())

```

This shows us that the only undefined symbol that is likely to be statistically significant is "". Lets have a closer look at that one.

```{r}
StormData %>%
    filter(CROPDMGEXP =="") %>%
    group_by(CROPDMGEXP,CROPDMG) %>%
    summarise(Total=n())
```

```{r}
StormData %>%
    filter(PROPDMGEXP =="") %>%
    group_by(PROPDMGEXP,PROPDMG) %>%
    summarise(Total=n())
```
So from this analysis, we can conclude that when the columns representing exponentiation are empty then the number of cases where the corresponding value column isnt equal to 0 is statistically insignificant.

Therefore for the purposes of this analysis, only the rows where PROPDMGEXP and CROPDMGEXP are equal to K, M or B are considered - all other observations will be set to NA so that they can be discarded in further analysis. We cannot just filter rows as on some occasions there are valid entries in PROPDMGEXP and undefined ones in CROPDMGEXP and vice-versa.


We use a dplyr pipe to start to work through this - first of all we replace K with 1000, M with 1000000 and then B with 1000000000 and then multiple the two columns togther.

```{r}

StormData <- StormData %>%
        #filter(PROPDMGEXP %in% c("K", "M", "B") & CROPDMGEXP %in% c("K", "M", "B")) %>%
        mutate(PROPDMGEXP=ifelse(!(PROPDMGEXP %in% c("K", "M", "B")) , NA, PROPDMGEXP)) %>%
        mutate(CROPDMGEXP=ifelse(!(CROPDMGEXP %in% c("K", "M", "B")) , NA, CROPDMGEXP)) %>%
        mutate(PROPDMGEXP=ifelse(PROPDMGEXP=="K", 1000, PROPDMGEXP)) %>%
        mutate(PROPDMGEXP=ifelse(PROPDMGEXP=="M", 1000000, PROPDMGEXP)) %>%
        mutate(PROPDMGEXP=ifelse(PROPDMGEXP=="B", 1000000000, PROPDMGEXP)) %>%
        mutate(CROPDMGEXP=ifelse(CROPDMGEXP=="K", 1000, CROPDMGEXP)) %>%
        mutate(CROPDMGEXP=ifelse(CROPDMGEXP=="M", 1000000, CROPDMGEXP)) %>%
        mutate(CROPDMGEXP=ifelse(CROPDMGEXP=="B", 1000000000, CROPDMGEXP)) %>%
        mutate(PROPDMGEVL=PROPDMG*as.numeric(PROPDMGEXP)) %>%
        mutate(CROPDMGEVL=CROPDMG*as.numeric(CROPDMGEXP))
```

Next lets investigate the event type column EVTYPE.

```{r}
length(unique(StormData$EVTYPE))
head(unique(StormData$EVTYPE), n=50)
```

One thing that sticks out immediately is that a number of the observation types are summary values so we'll remove those

```{r}
StormData <- StormData %>%
    filter(!grepl("ummary", EVTYPE, ignore.case=T))
```

Now lets try and use regular expressions to tidy EVTYPE up. Clearly there will be some arbitrariness of the choices in grouping the myriad of types in the raw data up into a manageable set of well defined parameters but that is inescapable and at least is well documented in the code below.

```{r}
## Use logical vectors to record the match

## Thunderstorms
TstmWind <- grepl("TSTM|LIGHTN.*|^THUNDE.*|THUNDERSTORM|TSTM  *WIND|THUNDERSTORM  *W|THUNDERSTORMS  *W|TSTMW|THUNDERSTORMW *|TSTM WND|THUDERSTORM WINDS|THUNERSTORM WINDS", StormData$EVTYPE, ignore.case=T )
StormData[TstmWind,"EVTYPE"] <- "Thunder"
## Snow
Snow <- grepl("SNOW|blizzard|sleet", StormData$EVTYPE, ignore.case=T )
StormData[Snow,"EVTYPE"] <- "Snow"
##HighWinds
HighWinds <- grepl("^High Wind|wind", StormData$EVTYPE, ignore.case=T )
StormData[HighWinds,"EVTYPE"] <- "Wind"
## Rain
Rain <- grepl("RAIN", StormData$EVTYPE, ignore.case=T )
StormData[Rain,"EVTYPE"] <- "Rain"
## Hail
Hail <- grepl("Hail", StormData$EVTYPE, ignore.case=T )
StormData[Hail,"EVTYPE"] <- "Hail"
## Extreme Storms
ExtStorm <- grepl("tornado|TORNDAO|hurricane|typhoon|Landspout|funnel|spout|whirl|winter storm|tropical|ICE STORM| DUST", StormData$EVTYPE, ignore.case=T )
StormData[ExtStorm,"EVTYPE"] <- "Ext Storm"
## Floods
Flood <- grepl("flood", StormData$EVTYPE, ignore.case=T )
StormData[Flood,"EVTYPE"] <- "Floods"
## Heat
Heat <- grepl("hot|heat|warm|high temp", StormData$EVTYPE, ignore.case=T )
StormData[Heat,"EVTYPE"] <- "Heat"
## Cold
Cold <- grepl("cold|low temp|frost|cool|freeze|.*ice.*|.*WINTER.*|.*freezing.*|.*wint.*|.*icy.*", StormData$EVTYPE, ignore.case=T )
StormData[Cold,"EVTYPE"] <- "Cold Spell "
## High Seas
HighSeas <- grepl("tsunami|wave|swell|tide|surf|.*SEA.*", StormData$EVTYPE, ignore.case=T )
StormData[HighSeas,"EVTYPE"] <- "High Seas"
##Dry Spell
DrySpell <- grepl("dry|drought|driest", StormData$EVTYPE, ignore.case=T )
StormData[DrySpell,"EVTYPE"] <- "Dry Spell"
##Wet Spell
WetSpell <- grepl("wet|.*precip.*", StormData$EVTYPE, ignore.case=T )
StormData[WetSpell,"EVTYPE"] <- "Wet Spell"
## Other
Other <- !(grepl("Thunder|Snow|Wind|Rain|Hail|Ext Storm|Floods|Heat|Cold Spell| High Seas| Dry Spell|Wet Spell", StormData$EVTYPE, ignore.case=T))
StormData[Other,"EVTYPE"] <- "Other"
```

The last bit of processing that we will do before starting to generate results is to generate a version of the data with the time dependency removed. The questions that we are attempting to answer are looking to investigate the dependencies on event types rather than time so we dont need the time dependency data at present.

```{r}
finalData <- StormData %>%
                group_by(EVTYPE, STATE) %>%
                summarise(FATALITIES=sum(FATALITIES), INJURIES=sum(INJURIES), PROPDAMAGE=sum(PROPDMGEVL, na.rm=TRUE), CROPDAMAGE=sum(PROPDMGEVL, na.rm=TRUE))
```
 When looking into how the weather affects population health in general, we use boxplots to understand the distribution across the US. In order to do this, we need to plot the log of the Y axis due to the wide degree of variation so we need to replace 0 values with NA.

```{r} 
healthData <- finalData[,c("EVTYPE","STATE","FATALITIES","INJURIES")]
healthData[healthData==0] <- NA
```

We need to do a similar analysis for the data regarding economic impact.

```{r} 
econData <- finalData[,c("EVTYPE","STATE","PROPDAMAGE","CROPDAMAGE")]
econData[econData==0] <- NA
```

# Results
## Macroscopic Analysis

Initially we investigate the macroscopic values across the whole of the US. In order to do this, we plot bar charts showing the sum of the quantities for each class of events.

```{r}
require(ggplot2)
require(gridExtra)
pa <- ggplot(data=finalData, aes(x=EVTYPE, y=FATALITIES)) +geom_bar(stat="identity")
pa <- pa + xlab("Event Type") +ylab("Fatalities")
pa <- pa + theme(axis.text.x = element_text(angle=90, vjust=0.5, hjust=1))
pa <- pa + ggtitle("Fatalities Caused by Weather")
pa <- pa + theme(title = element_text(size=10))
pb <- ggplot(data=finalData, aes(x=EVTYPE, y=INJURIES)) +geom_bar(stat="identity")
pb <- pb + xlab("Event Type") +ylab("Injuries")
pb <- pb + theme(axis.text.x = element_text(angle=90, vjust=0.5, hjust=1))
pb <- pb + ggtitle("Injuries Caused by Weather")
pb <- pb + theme(title = element_text(size=10))
pc <- ggplot(data=finalData, aes(x=EVTYPE, y=PROPDAMAGE)) +geom_bar(stat="identity")
pc <- pc + xlab("Event Type") +ylab("Property Damage  ($)") 
pc <- pc + theme(axis.text.x = element_text(angle=90, vjust=0.5, hjust=1))
pc <- pc + ggtitle("Property Damage Due to Weather")
pc <- pc + theme(title = element_text(size=10))
pd <- ggplot(data=finalData, aes(x=EVTYPE, y=CROPDAMAGE)) +geom_bar(stat="identity")
pd <- pd + xlab("Event Type") +ylab("Crop Damage  ($)") 
pd <- pd + theme(axis.text.x = element_text(angle=90, vjust=0.5, hjust=1))
pd <- pd + ggtitle("Crop Damage Due to Weather")
pd <- pd + theme(title = element_text(size=10))

grid.arrange(pa,pb,pc,pd, ncol=2)
```

This data is clearly dominated by Extreme Storms which have the highest value in both of the plots showing human impact and the second highest value in both the plots showing financial impact. This is not surprising given the catastrophic nature of the events contained in this group, for example Hurricanes and Tornados. 

When we consider the plots showing economic impact, Floods become much more important whereas in the other two plots they are not as prominent. This could be explained by the fact that in general, people have much more ability to get out of the way of a flood than they do for something like a Tornado. Buildings and crops however are static and so they are just as much at the mercy of a Flood as an Extreme Storm.

Heat appears to make a significant contribution to Fatalities only - this makes sense as heat is unlikely to injure someone but it is entirely possible to succumb to heat in the form of heat-stroke.

It is also interesting that Thunder appears to be significant in Fatalities - it would make sense to dig further into these figures in order to try and understand why this is significant. Similarly "Other" appears to be a significant contributor to economic impact - further analysis of the events that make up Other might be prudent.

However, we need to be careful - this data does not show the degree of spread in the results and so could potentially be dominated by a small number of unusually large values. We need to look at a more fine grained analysis - in order to do this, we look at box plots.

## Finer Grained Analysis
### Health Impact

We proceed to look at box plots that show the results pertaining to Injuries and Fatalities for individual states. Initially we plot the quantities that describe the impact of Weather events on health - namely Fatalities and Injuries.

```{r}
p1 <-ggplot(healthData, aes(y=INJURIES,x=EVTYPE)) + geom_boxplot() +  coord_trans(y = "log10")
p1 <- p1 + xlab("Event Type") +ylab("Injuries (log Scale)") 
p1 <- p1 + theme(axis.text.x = element_text(size=8)) + theme(axis.text.y = element_text(size=8))
p1 <- p1 + ggtitle("Injuries Caused by Severe Weather Events")
p2 <-ggplot(healthData, aes(y=FATALITIES,x=EVTYPE)) + geom_boxplot() +  coord_trans(y = "log10")
p2 <- p2 + xlab("Event Type") +ylab("Fatalities (log Scale)")
p2 <- p2 + theme(axis.text.x = element_text(size=8)) + theme(axis.text.y = element_text(size=8))
p2 <- p2 + ggtitle("Fatalities Caused by Severe Weather Events")
grid.arrange(p1,p2, ncol=1)
```

As expected, when we look at these box plots, further detail is exposed that isnt evident in the bar plots. Again we see that Extreme Storms are the most important when it comes to population health. However when we look at the median and indeed the inter-quartile range, Extreme Storms arent as dominant as they appear in the previous bar charts - this is because there are some extremely large outliers that exaggerate the domainance somewhat. It would be interesting to do further analysis in order to understand if these outliers are "true" values or the result of some clerical, computational or measurement error.

The boxplots strongly suggest that Thunder is important when considering the effects of weather on the population health - again this bears further investigation. Thunder storms obviously do come along with Hurricanes and Tornados so it might be that this is further indication of the importance of such events and potentially suggests that the classification of events used here might be sub-optimal. 

Large outliers also appear to explain the apparent importance of heat in Fatalities described above. Heat has a number of very large outlying values which could possibly be exaggerating its importance - again, further analysis would be helpful to understand the origin of these outliers.

It is not out of the realms of possibility that these outlying values are valid datapoints. We are after all considering an extremely inhomogenous geographical area. A hurricane in the wilds of Oregon would have a vastly different impact on population health than an equivalent storm hitting Downtown Manhattan.

## Econonomic Impact

Finally we turn to a more in-depth analysis of the impact of Weather Events on the economy. The plots below are box plots that show the results pertaining to $ impact of Property and Crop damage for individual states.

```{r}
p3 <-ggplot(econData, aes(y=PROPDAMAGE,x=EVTYPE)) + geom_boxplot() +  coord_trans(y = "log10")
p3 <- p3 + xlab("Event Type") +ylab("Property Damage  ($ -log Scale)") 
p3 <- p3 + theme(axis.text.x = element_text(size=8)) + theme(axis.text.y = element_text(size=8))
p3 <- p3 + ggtitle("Property Damage Caused by Severe Weather Events")
p4 <-ggplot(econData, aes(y=CROPDAMAGE,x=EVTYPE)) + geom_boxplot() +  coord_trans(y = "log10")
p4 <- p4 + xlab("Event Type") +ylab("Crop Damage ($ - log Scale)")
p4 <- p4 + theme(axis.text.x = element_text(size=8)) + theme(axis.text.y = element_text(size=8))
p4 <- p4 + ggtitle("Crop Damage Caused by Severe Weather Events")
grid.arrange(p3,p4, ncol=1)
```

The thing that initially strikes you when considering these values is the potential impact of outliers. There are more outliers here than there were for the health data and some of them are huge. 

Extreme Storms again are the dominant factor and in contradiction of the bar charts, the median value is higher than for that of floods. The outliers show why this is the case - floods has one outlier that is an order of magnitude than any other which, given that we use a log scale, sticks out that something that bears further investigation. If this value is due to some kind of error then it will be falsely inflating the importance of floods - if it is a valid result then it suggests that a freak event has skewed the figures to make floods appear more important than they normally are.

The other thing that is visible from these plots is that all the weather types across the board have more uniform impact in terms of the economy than public health.


#Conclusions

Extreme Storms appear to be the most harmful events with respect to the health of the population.

Extreme Storms and Floods appear to be the dominant types of events in terms of economic consequences.

The figures for floods need to be looked at more closesly as there are some suspiciously large outliers there that could potentially be skewing the figures.